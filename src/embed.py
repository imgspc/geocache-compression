from __future__ import annotations

import argparse
import json
import numpy as np
import os
import struct
import sys

from typing import Any, Optional, Iterable, Union
from numpy.typing import DTypeLike
from embedding import embedding
from embedding import clustering
from embedding.io import Header, read_binfile, parse_json

# Inputs:
#       .json -- provides nsamples, type, size, extent
#       .bin -- an ndarray of shape (nsamples, size, extent) and the given type; must match an entry in the json file
#
# Output:
#       .embed-header.bin
#       .embed.bin
#       .embed-clusters.bin
#
# The embed-header is a list of Embedding objects, serialized. One object per vertex.
#
# The embed file is a list of reduced-dimension ndarrays, one per vertex. The overall shape
# is a ragged array of (size, nsamples, k) where k may vary per vertex.
#
# See reconstruct.py to lossily reverse from the embedded data to the original.
#


def convert(jsonfile: str, binfile: str, quality: float, clustersize: int) -> str:
    """
    Convert the input file (with metadata in the json file) to embed files.
    """
    package = parse_json(jsonfile)
    header = package.get_header(binfile)
    f = read_binfile(header)
    print(f"read {binfile} as {header}")
    header.verify_shape(f)

    # Form the clusters
    cover = clustering.cluster_by_index(header.size, clustersize)
    print(f"found {cover.nsubsets} clusters")

    # TODO: parallelize the computation.
    clusters = list(clustering.slice(f, cover))
    embedded = [
        embedding.PCAEmbedding.from_data(cluster, quality) for cluster in clusters
    ]

    basename = os.path.splitext(binfile)[0]
    headersbin = basename + ".embed-header.bin"
    projectedbin = basename + ".embed.bin"
    clusterbin = basename + ".embed-clusters.bin"
    with open(headersbin, "wb") as headerfile:
        with open(projectedbin, "wb") as projectedfile:
            for i, cluster in enumerate(clusters):
                headerfile.write(embedding.serialize(embedded[i]))
                projected = embedded[i].project(cluster)
                projectedfile.write(projected.tobytes())
            projectedfilesize = projectedfile.tell()
        headerfilesize = headerfile.tell()
    with open(clusterbin, "wb") as clusterfile:
        clusterfile.write(cover.tobytes())
        clusterfilesize = clusterfile.tell()
    print(f"Wrote {clusterfilesize + headerfilesize + projectedfilesize} bytes")

    return projectedbin


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Embed a property from an alembic file into lower dimension.",
        epilog="Use abc-parse to generate the json file and abc-separate to generate the bin files.",
    )
    parser.add_argument("json", help="Json file generated by abc-parse")
    parser.add_argument("binfile", help="Binary file generated by abc-separate")
    parser.add_argument(
        "--quality",
        help="Percentage of variance to explain. Higher is more data, less error",
        default=0.9999,
    )
    parser.add_argument(
        "--clustersize",
        help="Size of clusters to build. Higher is less data, potentially more error",
        default=100,
    )
    args = parser.parse_args()
    outname = convert(
        args.json, args.binfile, float(args.quality), int(args.clustersize)
    )
    print(f"output written to {outname}")
