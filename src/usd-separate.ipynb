{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d18d4a-37a3-4afa-b0d1-10db2da4c3e0",
   "metadata": {},
   "source": [
    "To start running this notebook: in a shell, go to the home directory of the github repo.\n",
    "```\n",
    "cd src\n",
    "conda create geocache python=3.11\n",
    "conda activate geocache\n",
    "conda install numpy jupyter\n",
    "jupyter notebook usd-separate.ipynb\n",
    "```\n",
    "Then you can shift-enter to run each cell here.\n",
    "\n",
    "To run the Alembic parts you'll need to have run the Running Alembic part of the [README](https://github.com/imgspc/geocache-compression/blob/main/README.md#running-alembic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec080a14-13fe-497f-aa5f-f0f318aea572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have USD installed.\n",
    "!pip install usd-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3448c09-5060-43eb-9bc9-b9bd5094658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some file locations. I've put everything in $HOME/projects, but you can change these paths.\n",
    "from pathlib import Path\n",
    "\n",
    "home = Path.home()\n",
    "infile = str(home / \"projects/ALab/ALab/entry.usda\")\n",
    "outdir = str(home / \"projects/geocache-compression/build\")\n",
    "octopus = str(home / \"projects/geocache-compression/build/octopus.json\")\n",
    "octopus_bindir = home/\"projects/geocache-compression/build\"\n",
    "\n",
    "clustersize = 10000\n",
    "quality = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ccec2-b097-4890-86cd-fb467f2ed847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pxr import Usd\n",
    "from embedding.io import separate_usd\n",
    "from embedding.io import create_embedding\n",
    "from embedding.io import read_embedding\n",
    "from embedding.metric import Report\n",
    "from embedding.io import read_binfile, parse_json_file, run_all_reports\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6a601-66be-44f7-9b0b-ef45b1b11fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = Usd.Stage.Open(infile)\n",
    "mpu = stage.GetMetadata(\"metersPerUnit\")\n",
    "print(mpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7715b64-38f6-4674-b40e-15efbc88ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "package = separate_usd(infile, outdir, verbose=False)\n",
    "print(f\"{package.inputfile} has {len(package.headers)} animations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c14d98-d0d0-4e14-9c54-dbf2a4a96080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test just doing one embedding.\n",
    "header = max(package.headers, key=lambda h: h.numbytes())  # compress the biggest file\n",
    "# header = package.get_header(\"/root/remi/head_M_hrc/GEO/head_M_hrc/facePlate_M_geo\")\n",
    "print(f\"{header}\")\n",
    "files = create_embedding(header, clustersize=clustersize, quality=quality, verbose=True)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5d73a-0ebc-4a81-83af-ff2902e184d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "postdata = read_embedding(header, files, verbose=True)\n",
    "predata = read_binfile(header)\n",
    "report = Report(predata, postdata, sum(os.path.getsize(path) for path in files))\n",
    "print(f\"{header.path}\")\n",
    "report.print_report(mpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf7ff7-7cbf-40ea-97b9-e909a1baf65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test *all* the animations.\n",
    "reports = run_all_reports(package, quality=quality, clustersize=clustersize, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae7b45-fb4c-4c6e-8656-f1336638dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with the overall set of reports.\n",
    "orig = sum(r.original_size for r in reports.values())\n",
    "compressed = sum(r.compressed_size for r in reports.values())\n",
    "print(f\"{orig} vs {compressed} -- {1-compressed/orig:.2%} compression\")\n",
    "\n",
    "h = max(r.hausdorff for r in reports.values()) * mpu\n",
    "linf = max(r.Linf for r in reports.values()) * mpu\n",
    "print(f\"Max error: {h} m distance, {linf} m any single coordinate\")\n",
    "\n",
    "corrected = max(r.corrected_Linf for r in reports.values()) * mpu\n",
    "uncorrected = sum(r.numuncorrectable for r in reports.values())\n",
    "numvalues = sum(r.original_numvalues for r in reports.values())\n",
    "print(f\"{uncorrected} uncorrectable out of {numvalues} ({uncorrected/numvalues:%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dbdfa-fe37-422e-b48e-abc782ac30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Alembic fun times\n",
    "abc_package = parse_json_file(octopus)\n",
    "for h in abc_package.headers:\n",
    "    if not os.path.isabs(h.binpath):\n",
    "        h.binpath = str(octopus_bindir / h.binpath)\n",
    "\n",
    "mpu = 0.01\n",
    "reports = run_all_reports(abc_package, clustersize=clustersize, quality=quality, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b15fb-8249-40aa-b7ac-0b8e1c3a2958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
