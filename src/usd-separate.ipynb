{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee923b4",
   "metadata": {},
   "source": [
    "To start running this notebook: in a shell, go to the home directory of the github repo.\n",
    "```\n",
    "cd src\n",
    "conda create geocache python=3.11\n",
    "conda activate geocache\n",
    "conda install numpy jupyter usd-core\n",
    "jupyter notebook usd-separate.ipynb\n",
    "```\n",
    "Then you can shift-enter to run each cell here.\n",
    "\n",
    "To run the Alembic parts you'll need to have run the Running Alembic part of the [README](https://github.com/imgspc/geocache-compression/blob/main/README.md#running-alembic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings start here. Evaluate this cell whenever needed.\n",
    "from pxr import Usd\n",
    "from embedding import clustering\n",
    "from embedding.embedding import PCAEmbedding, RoundedPCAEmbedding, embed_or_raw\n",
    "from embedding.io import separate_usd\n",
    "from embedding.io import create_embedding\n",
    "from embedding.io import read_embedding\n",
    "from embedding.metric import Report\n",
    "from embedding.io import read_binfile, parse_json_file, run_all_reports\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "############# Settings until the next line of ########\n",
    "home = Path.home()\n",
    "infile = str(home / \"projects/ALab/ALab/entry.usda\")\n",
    "outdir = str(home / \"projects/geocache-compression/build\")\n",
    "octopus = str(home / \"projects/geocache-compression/build/octopus.json\")\n",
    "octopus_bindir = home / \"projects/geocache-compression/build\"\n",
    "\n",
    "check_static = False\n",
    "cluster_fn = clustering.cluster_last_axis  # clustering.cluster_near_quaternions\n",
    "embed_cls = None\n",
    "clustersize = 1000\n",
    "quality_meters = 1e-4\n",
    "quality_fraction = 0.999\n",
    "\n",
    "\n",
    "########################################\n",
    "embed_fn = embed_or_raw\n",
    "\n",
    "\n",
    "def quality(mpu: float):\n",
    "    if embed_cls is RoundedPCAEmbedding:\n",
    "        return quality_meters / mpu\n",
    "    else:\n",
    "        return quality_fraction\n",
    "\n",
    "\n",
    "if check_static:\n",
    "    import functools\n",
    "\n",
    "    cluster_fn = functools.partial(\n",
    "        clustering.cluster_static_first, cluster_fn=cluster_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004143f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files.\n",
    "stage = Usd.Stage.Open(infile)\n",
    "usd_mpu = stage.GetMetadata(\"metersPerUnit\")\n",
    "usd_package = separate_usd(infile, outdir, verbose=False)\n",
    "print(\n",
    "    f\"{usd_package.inputfile} has {len(usd_package.headers)} animations, mpu {usd_mpu}\"\n",
    ")\n",
    "\n",
    "abc_mpu = 0.01\n",
    "abc_package = parse_json_file(octopus)\n",
    "for h in abc_package.headers:\n",
    "    if not os.path.isabs(h.binpath):\n",
    "        h.binpath = str(octopus_bindir / h.binpath)\n",
    "print(\n",
    "    f\"{abc_package.inputfile} has {len(abc_package.headers)} animations, mpu {abc_mpu}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d930b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test just doing one embedding.\n",
    "# header = max(\n",
    "#    usd_package.headers, key=lambda h: h.numbytes()\n",
    "# )  # compress the biggest file\n",
    "# header = usd_package.get_header(\"/root/remi/head_M_hrc/GEO/head_M_hrc/facePlate_M_geo\")\n",
    "header = usd_package.get_header(\n",
    "    \"/root/remi/body_M_hrc/GEO/body_M_hrc/flag_M_hrc/flag_M_geo\"\n",
    ")\n",
    "print(f\"{header}\")\n",
    "files = create_embedding(\n",
    "    header,\n",
    "    cluster_fn=cluster_fn,\n",
    "    embed_fn=embed_fn,\n",
    "    quality=quality(usd_mpu),\n",
    "    cluster_size=clustersize,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(files)\n",
    "\n",
    "postdata = read_embedding(header, files, verbose=True)\n",
    "predata = read_binfile(header)\n",
    "report = Report(predata, postdata, sum(os.path.getsize(path) for path in files))\n",
    "print(f\"{header.path}\")\n",
    "report.print_report(usd_mpu)\n",
    "for path in files:\n",
    "    print(f\"  {os.path.getsize(path)} {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test *all* the animations.\n",
    "reports = run_all_reports(\n",
    "    usd_package,\n",
    "    quality=quality(usd_mpu),\n",
    "    cluster_fn=cluster_fn,\n",
    "    embed_fn=embed_fn,\n",
    "    cluster_size=clustersize,\n",
    "    verbose=True,\n",
    ")\n",
    "overall = Report.combine_reports(reports)\n",
    "overall.print_report(usd_mpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Alembic fun times\n",
    "reports = run_all_reports(\n",
    "    abc_package,\n",
    "    cluster_fn=cluster_fn,\n",
    "    cluster_size=clustersize,\n",
    "    embed_fn=embed_fn,\n",
    "    quality=quality(abc_mpu),\n",
    "    verbose=True,\n",
    ")\n",
    "overall = Report.combine_reports(reports.values())\n",
    "overall.print_report(abc_mpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73251958",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the full report for all tests:\n",
    "class Scenario:\n",
    "    def __init__(self, package, packagename, quality, cluster_fn, embed_fn):\n",
    "        self.package = package\n",
    "        self.packagename = packagename\n",
    "        self.quality = quality\n",
    "        self.cluster_fn = cluster_fn\n",
    "        self.embed_fn = embed_fn\n",
    "\n",
    "    def run(self):\n",
    "        print(\n",
    "            f\"************************************\\n\"\n",
    "            f\"Running: {self.packagename} with quality {self.quality} {self.cluster_fn.__qualname__} / {self.embed_fn.__qualname__}\"\n",
    "        )\n",
    "        reports = run_all_reports(\n",
    "            self.package,\n",
    "            cluster_fn=self.cluster_fn,\n",
    "            embed_fn=self.embed_fn,\n",
    "            cluster_size=clustersize,\n",
    "            quality=self.quality,\n",
    "            verbose=True,\n",
    "        )\n",
    "        summary = Summary(self, Report.combine_reports(reports.values()))\n",
    "        print(f\"{summary}\\n\" f\"************************************\")\n",
    "        return summary\n",
    "\n",
    "\n",
    "class Summary:\n",
    "    def __init__(self, scenario, report):\n",
    "        self.packagename = scenario.packagename\n",
    "        self.quality = scenario.quality\n",
    "        self.clustername = scenario.cluster_fn.__qualname__\n",
    "        self.embedname = scenario.embed_fn.__qualname__\n",
    "        self.report = report\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.packagename} , {self.clustername} , {self.embedname} , {self.quality} , {self.report.compression_ratio:.2%} , {self.report.hausdorff}\"\n",
    "\n",
    "\n",
    "def make_scenarios():\n",
    "    return [\n",
    "        Scenario(package, packagename, quality, cluster_fn, embed_fn)\n",
    "        for (package, packagename, mpu) in (\n",
    "            (usd_package, \"usd\", usd_mpu),\n",
    "            # (abc_package, \"abc\", abc_mpu),\n",
    "        )\n",
    "        for (embed_fn, quality) in (\n",
    "            # (RoundedPCAEmbedding.from_data, 1e-2 / mpu),\n",
    "            (embed_or_raw, 1e-4 / mpu),\n",
    "            # (RoundedPCAEmbedding.from_data, 1e-4 / mpu),\n",
    "            # (PCAEmbedding.from_data, 0.99),\n",
    "            # (PCAEmbedding.from_data, 0.999),\n",
    "        )\n",
    "        for cluster_fn in (\n",
    "            # clustering.cluster_monolithic,\n",
    "            clustering.cluster_by_index,\n",
    "            # clustering.cluster_pca_kmeans,\n",
    "            # clustering.cluster_kmeans,\n",
    "            # clustering.cluster_near_quaternions,\n",
    "            clustering.cluster_first_axis,\n",
    "            clustering.cluster_last_axis,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "# scenarios = [Scenario(abc_package, \"abc\", quality(abc_mpu), clustering.cluster_by_index, embed_fn)]\n",
    "scenarios = make_scenarios()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6063c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a long time!\n",
    "summaries = [scenario.run() for scenario in scenarios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for summary in summaries:\n",
    "    print(f\"{summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
